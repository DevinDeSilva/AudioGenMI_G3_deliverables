{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a800eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import dycomutils\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "from dotenv import load_dotenv\n",
    "import dycomutils\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torchaudio\n",
    "#from torch.utils import tensorboard\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load Configs\n",
    "load_dotenv()\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "# run = neptune.init_run(\n",
    "#     project=\"Botz/Audio-MI\",\n",
    "#     name=\"sinc-net-training\",\n",
    "#     api_token=os.getenv(\"NEPTUNE_API_TOKEN\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca763a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(x, dim):\n",
    "    xsize = x.size()\n",
    "    dim = x.dim() + dim if dim < 0 else dim\n",
    "    x = x.contiguous()\n",
    "    x = x.view(-1, *xsize[dim:])\n",
    "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
    "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
    "    return x.view(xsize)\n",
    "\n",
    "\n",
    "def sinc(band,t_right):\n",
    "    y_right= torch.sin(2*math.pi*band*t_right)/(2*math.pi*band*t_right)\n",
    "    y_left= flip(y_right,0)\n",
    "\n",
    "    y=torch.cat([y_left,Variable(torch.ones(1)).cuda(),y_right])\n",
    "\n",
    "    return y\n",
    "    \n",
    "\n",
    "class SincConv_fast(nn.Module):\n",
    "    \"\"\"Sinc-based convolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : `int`\n",
    "        Number of input channels. Must be 1.\n",
    "    out_channels : `int`\n",
    "        Number of filters.\n",
    "    kernel_size : `int`\n",
    "        Filter length.\n",
    "    sample_rate : `int`, optional\n",
    "        Sample rate. Defaults to 16000.\n",
    "    Usage\n",
    "    -----\n",
    "    See `torch.nn.Conv1d`\n",
    "    Reference\n",
    "    ---------\n",
    "    Mirco Ravanelli, Yoshua Bengio,\n",
    "    \"Speaker Recognition from raw waveform with SincNet\".\n",
    "    https://arxiv.org/abs/1808.00158\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
    "\n",
    "        super(SincConv_fast,self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "            #msg = (f'SincConv only support one input channel '\n",
    "            #       f'(here, in_channels = {in_channels:d}).')\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size%2==0:\n",
    "            self.kernel_size=self.kernel_size+1\n",
    "            \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
    "        low_hz = 30\n",
    "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
    "\n",
    "        mel = np.linspace(self.to_mel(low_hz),\n",
    "                          self.to_mel(high_hz),\n",
    "                          self.out_channels + 1)\n",
    "        hz = self.to_hz(mel)\n",
    "        \n",
    "\n",
    "        # filter lower frequency (out_channels, 1)\n",
    "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
    "\n",
    "        # filter frequency band (out_channels, 1)\n",
    "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
    "\n",
    "        # Hamming window\n",
    "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
    "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
    "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
    "\n",
    "\n",
    "        # (1, kernel_size/2)\n",
    "        n = (self.kernel_size - 1) / 2.0\n",
    "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
    "            Batch of waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
    "            Batch of sinc filters activations.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_ = self.n_.to(waveforms.device)\n",
    "\n",
    "        self.window_ = self.window_.to(waveforms.device)\n",
    "\n",
    "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
    "        \n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
    "        band=(high-low)[:,0]\n",
    "        \n",
    "        f_times_t_low = torch.matmul(low, self.n_)\n",
    "        f_times_t_high = torch.matmul(high, self.n_)\n",
    "\n",
    "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
    "        band_pass_center = 2*band.view(-1,1)\n",
    "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
    "        \n",
    "        \n",
    "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
    "\n",
    "        \n",
    "        band_pass = band_pass / (2*band[:,None])\n",
    "        \n",
    "\n",
    "        self.filters = (band_pass).view(\n",
    "            self.out_channels, 1, self.kernel_size)\n",
    "\n",
    "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                         bias=None, groups=1) \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class sinc_conv(nn.Module):\n",
    "\n",
    "    def __init__(self, N_filt,Filt_dim,fs):\n",
    "        super(sinc_conv,self).__init__()\n",
    "\n",
    "        # Mel Initialization of the filterbanks\n",
    "        low_freq_mel = 80\n",
    "        high_freq_mel = (2595 * np.log10(1 + (fs / 2) / 700))  # Convert Hz to Mel\n",
    "        mel_points = np.linspace(low_freq_mel, high_freq_mel, N_filt)  # Equally spaced in Mel scale\n",
    "        f_cos = (700 * (10**(mel_points / 2595) - 1)) # Convert Mel to Hz\n",
    "        b1=np.roll(f_cos,1)\n",
    "        b2=np.roll(f_cos,-1)\n",
    "        b1[0]=30\n",
    "        b2[-1]=(fs/2)-100\n",
    "                \n",
    "        self.freq_scale=fs*1.0\n",
    "        self.filt_b1 = nn.Parameter(torch.from_numpy(b1/self.freq_scale))\n",
    "        self.filt_band = nn.Parameter(torch.from_numpy((b2-b1)/self.freq_scale))\n",
    "\n",
    "        \n",
    "        self.N_filt=N_filt\n",
    "        self.Filt_dim=Filt_dim\n",
    "        self.fs=fs\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        filters=Variable(torch.zeros((self.N_filt,self.Filt_dim))).cuda()\n",
    "        N=self.Filt_dim\n",
    "        t_right=Variable(torch.linspace(1, (N-1)/2, steps=int((N-1)/2))/self.fs).cuda()\n",
    "        \n",
    "        \n",
    "        min_freq=50.0;\n",
    "        min_band=50.0;\n",
    "        \n",
    "        filt_beg_freq=torch.abs(self.filt_b1)+min_freq/self.freq_scale\n",
    "        filt_end_freq=filt_beg_freq+(torch.abs(self.filt_band)+min_band/self.freq_scale)\n",
    "       \n",
    "        n=torch.linspace(0, N, steps=N)\n",
    "\n",
    "        # Filter window (hamming)\n",
    "        window=0.54-0.46*torch.cos(2*math.pi*n/N);\n",
    "        window=Variable(window.float().cuda())\n",
    "\n",
    "        \n",
    "        for i in range(self.N_filt):\n",
    "                        \n",
    "            low_pass1 = 2*filt_beg_freq[i].float()*sinc(filt_beg_freq[i].float()*self.freq_scale,t_right)\n",
    "            low_pass2 = 2*filt_end_freq[i].float()*sinc(filt_end_freq[i].float()*self.freq_scale,t_right)\n",
    "            band_pass=(low_pass2-low_pass1)\n",
    "\n",
    "            band_pass=band_pass/torch.max(band_pass)\n",
    "\n",
    "            filters[i,:]=band_pass.cuda()*window\n",
    "\n",
    "        out=F.conv1d(x, filters.view(self.N_filt,1,self.Filt_dim))\n",
    "    \n",
    "        return out\n",
    "    \n",
    "\n",
    "def act_fun(act_type):\n",
    "\n",
    " if act_type==\"relu\":\n",
    "    return nn.ReLU()\n",
    "            \n",
    " if act_type==\"tanh\":\n",
    "    return nn.Tanh()\n",
    "            \n",
    " if act_type==\"sigmoid\":\n",
    "    return nn.Sigmoid()\n",
    "           \n",
    " if act_type==\"leaky_relu\":\n",
    "    return nn.LeakyReLU(0.2)\n",
    "            \n",
    " if act_type==\"elu\":\n",
    "    return nn.ELU()\n",
    "                     \n",
    " if act_type==\"softmax\":\n",
    "    return nn.LogSoftmax(dim=1)\n",
    "        \n",
    " if act_type==\"linear\":\n",
    "    return nn.LeakyReLU(1) # initializzed like this, but not used in forward!\n",
    "            \n",
    "            \n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, options):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.input_dim=int(options['input_dim'])\n",
    "        self.fc_lay=options['fc_lay']\n",
    "        self.fc_drop=options['fc_drop']\n",
    "        self.fc_use_batchnorm=options['fc_use_batchnorm']\n",
    "        self.fc_use_laynorm=options['fc_use_laynorm']\n",
    "        self.fc_use_laynorm_inp=options['fc_use_laynorm_inp']\n",
    "        self.fc_use_batchnorm_inp=options['fc_use_batchnorm_inp']\n",
    "        self.fc_act=options['fc_act']\n",
    "        \n",
    "       \n",
    "        self.wx  = nn.ModuleList([])\n",
    "        self.bn  = nn.ModuleList([])\n",
    "        self.ln  = nn.ModuleList([])\n",
    "        self.act = nn.ModuleList([])\n",
    "        self.drop = nn.ModuleList([])\n",
    "       \n",
    "\n",
    "       \n",
    "        # input layer normalization\n",
    "        if self.fc_use_laynorm_inp:\n",
    "           self.ln0=LayerNorm(self.input_dim)\n",
    "          \n",
    "        # input batch normalization    \n",
    "        if self.fc_use_batchnorm_inp:\n",
    "           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n",
    "           \n",
    "           \n",
    "        self.N_fc_lay=len(self.fc_lay)\n",
    "             \n",
    "        current_input=self.input_dim\n",
    "        \n",
    "        # Initialization of hidden layers\n",
    "        \n",
    "        for i in range(self.N_fc_lay):\n",
    "            \n",
    "         # dropout\n",
    "         self.drop.append(nn.Dropout(p=self.fc_drop[i]))\n",
    "         \n",
    "         # activation\n",
    "         self.act.append(act_fun(self.fc_act[i]))\n",
    "         \n",
    "         \n",
    "         add_bias=True\n",
    "         \n",
    "         # layer norm initialization\n",
    "         self.ln.append(LayerNorm(self.fc_lay[i]))\n",
    "         self.bn.append(nn.BatchNorm1d(self.fc_lay[i],momentum=0.05))\n",
    "         \n",
    "         if self.fc_use_laynorm[i] or self.fc_use_batchnorm[i]:\n",
    "             add_bias=False\n",
    "         \n",
    "              \n",
    "         # Linear operations\n",
    "         self.wx.append(nn.Linear(current_input, self.fc_lay[i],bias=add_bias))\n",
    "         \n",
    "         # weight initialization\n",
    "         self.wx[i].weight = torch.nn.Parameter(torch.Tensor(self.fc_lay[i],current_input).uniform_(-np.sqrt(0.01/(current_input+self.fc_lay[i])),np.sqrt(0.01/(current_input+self.fc_lay[i]))))\n",
    "         self.wx[i].bias = torch.nn.Parameter(torch.zeros(self.fc_lay[i]))\n",
    "         \n",
    "         current_input=self.fc_lay[i]\n",
    "         \n",
    "         \n",
    "    def forward(self, x):\n",
    "        \n",
    "      # Applying Layer/Batch Norm\n",
    "      if bool(self.fc_use_laynorm_inp):\n",
    "        x=self.ln0((x))\n",
    "        \n",
    "      if bool(self.fc_use_batchnorm_inp):\n",
    "        x=self.bn0((x))\n",
    "        \n",
    "      for i in range(self.N_fc_lay):\n",
    "\n",
    "        if self.fc_act[i]!='linear':\n",
    "            \n",
    "          if self.fc_use_laynorm[i]:\n",
    "           x = self.drop[i](self.act[i](self.ln[i](self.wx[i](x))))\n",
    "          \n",
    "          if self.fc_use_batchnorm[i]:\n",
    "           x = self.drop[i](self.act[i](self.bn[i](self.wx[i](x))))\n",
    "          \n",
    "          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n",
    "           x = self.drop[i](self.act[i](self.wx[i](x)))\n",
    "           \n",
    "        else:\n",
    "          if self.fc_use_laynorm[i]:\n",
    "           x = self.drop[i](self.ln[i](self.wx[i](x)))\n",
    "          \n",
    "          if self.fc_use_batchnorm[i]:\n",
    "           x = self.drop[i](self.bn[i](self.wx[i](x)))\n",
    "          \n",
    "          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n",
    "           x = self.drop[i](self.wx[i](x)) \n",
    "          \n",
    "      return x\n",
    "\n",
    "\n",
    "\n",
    "class SincNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,options):\n",
    "       super(SincNet,self).__init__()\n",
    "    \n",
    "       self.cnn_N_filt=options['cnn_N_filt']\n",
    "       self.cnn_len_filt=options['cnn_len_filt']\n",
    "       self.cnn_max_pool_len=options['cnn_max_pool_len']\n",
    "       \n",
    "       \n",
    "       self.cnn_act=options['cnn_act']\n",
    "       self.cnn_drop=options['cnn_drop']\n",
    "       \n",
    "       self.cnn_use_laynorm=options['cnn_use_laynorm']\n",
    "       self.cnn_use_batchnorm=options['cnn_use_batchnorm']\n",
    "       self.cnn_use_laynorm_inp=options['cnn_use_laynorm_inp']\n",
    "       self.cnn_use_batchnorm_inp=options['cnn_use_batchnorm_inp']\n",
    "       \n",
    "       self.input_dim=int(options['input_dim'])\n",
    "       \n",
    "       self.fs=options['fs']\n",
    "       \n",
    "       self.N_cnn_lay=len(options['cnn_N_filt'])\n",
    "       self.conv  = nn.ModuleList([])\n",
    "       self.bn  = nn.ModuleList([])\n",
    "       self.ln  = nn.ModuleList([])\n",
    "       self.act = nn.ModuleList([])\n",
    "       self.drop = nn.ModuleList([])\n",
    "       \n",
    "             \n",
    "       if self.cnn_use_laynorm_inp:\n",
    "           self.ln0=LayerNorm(self.input_dim)\n",
    "           \n",
    "       if self.cnn_use_batchnorm_inp:\n",
    "           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n",
    "           \n",
    "       current_input=self.input_dim \n",
    "       \n",
    "       for i in range(self.N_cnn_lay):\n",
    "         \n",
    "         N_filt=int(self.cnn_N_filt[i])\n",
    "         len_filt=int(self.cnn_len_filt[i])\n",
    "         \n",
    "         # dropout\n",
    "         self.drop.append(nn.Dropout(p=self.cnn_drop[i]))\n",
    "         \n",
    "         # activation\n",
    "         self.act.append(act_fun(self.cnn_act[i]))\n",
    "                    \n",
    "         # layer norm initialization         \n",
    "         self.ln.append(LayerNorm([N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])]))\n",
    "\n",
    "         self.bn.append(nn.BatchNorm1d(N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i]),momentum=0.05))\n",
    "            \n",
    "\n",
    "         if i==0:\n",
    "          self.conv.append(SincConv_fast(self.cnn_N_filt[0],self.cnn_len_filt[0],self.fs))\n",
    "              \n",
    "         else:\n",
    "          self.conv.append(nn.Conv1d(self.cnn_N_filt[i-1], self.cnn_N_filt[i], self.cnn_len_filt[i]))\n",
    "          \n",
    "         current_input=int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])\n",
    "\n",
    "         \n",
    "       self.out_dim=current_input*N_filt\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "       batch=x.shape[0]\n",
    "       seq_len=x.shape[1]\n",
    "       \n",
    "       if bool(self.cnn_use_laynorm_inp):\n",
    "        x=self.ln0((x))\n",
    "        \n",
    "       if bool(self.cnn_use_batchnorm_inp):\n",
    "        x=self.bn0((x))\n",
    "        \n",
    "       x=x.view(batch,1,seq_len)\n",
    "\n",
    "       \n",
    "       for i in range(self.N_cnn_lay):\n",
    "           \n",
    "         if self.cnn_use_laynorm[i]:\n",
    "          if i==0:\n",
    "           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(torch.abs(self.conv[i](x)), self.cnn_max_pool_len[i]))))  \n",
    "          else:\n",
    "           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))   \n",
    "          \n",
    "         if self.cnn_use_batchnorm[i]:\n",
    "          x = self.drop[i](self.act[i](self.bn[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))\n",
    "\n",
    "         if self.cnn_use_batchnorm[i]==False and self.cnn_use_laynorm[i]==False:\n",
    "          x = self.drop[i](self.act[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i])))\n",
    "\n",
    "       \n",
    "       x = x.view(batch,-1)\n",
    "\n",
    "       return x\n",
    "   \n",
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "    else:\n",
    "         raise ValueError \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adea0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESAMPLE_RATE = 6000\n",
    "\n",
    "fs=f\"{RESAMPLE_RATE}\"\n",
    "cw_len=\"1024\"\n",
    "cw_shift=\"10\"   \n",
    "\n",
    "cnn_N_filt=\"100,80,80\"\n",
    "cnn_len_filt=\"251,5,5\"\n",
    "cnn_max_pool_len=\"3,3,3\"\n",
    "cnn_use_laynorm_inp=\"True\"\n",
    "cnn_use_batchnorm_inp=\"False\"\n",
    "cnn_use_laynorm=\"True,True,True\"\n",
    "cnn_use_batchnorm=\"False,False,False\"\n",
    "cnn_act=\"leaky_relu,leaky_relu,leaky_relu\"\n",
    "cnn_drop=\"0.1,0.1,0.1\"\n",
    "\n",
    "\n",
    "fc_lay=\"2048,2048,2048\"\n",
    "fc_drop=\"0.1,0.1,0.1\"\n",
    "fc_use_laynorm_inp=\"True\"\n",
    "fc_use_batchnorm_inp=\"False\"\n",
    "fc_use_batchnorm=\"True,True,True\"\n",
    "fc_use_laynorm=\"False,False,False\"\n",
    "fc_act=\"leaky_relu,leaky_relu,leaky_relu\"\n",
    "\n",
    "class_lay=\"2\"\n",
    "class_drop=\"0.0\"\n",
    "class_use_laynorm_inp=\"False\"\n",
    "class_use_batchnorm_inp=\"False\"\n",
    "class_use_batchnorm=\"False\"\n",
    "class_use_laynorm=\"False\"\n",
    "class_act=\"softmax\"\n",
    "\n",
    "lr=\"0.0004\"\n",
    "batch_size=\"128\"\n",
    "N_epochs=\"1500\"\n",
    "N_batches=\"800\"\n",
    "N_eval_epoch=\"8\"\n",
    "seed=\"1234\"\n",
    "\n",
    "# %%\n",
    "cnn_N_filt=list(map(int, cnn_N_filt.split(',')))\n",
    "cnn_len_filt=list(map(int, cnn_len_filt.split(',')))\n",
    "cnn_max_pool_len=list(map(int, cnn_max_pool_len.split(',')))\n",
    "cnn_use_laynorm_inp=str_to_bool(cnn_use_laynorm_inp)\n",
    "cnn_use_batchnorm_inp=str_to_bool(cnn_use_batchnorm_inp)\n",
    "cnn_use_laynorm=list(map(str_to_bool, cnn_use_laynorm.split(',')))\n",
    "cnn_use_batchnorm=list(map(str_to_bool, cnn_use_batchnorm.split(',')))\n",
    "cnn_act=list(map(str, cnn_act.split(',')))\n",
    "cnn_drop=list(map(float, cnn_drop.split(',')))\n",
    "\n",
    "\n",
    "#[dnn]\n",
    "fc_lay=list(map(int, fc_lay.split(',')))\n",
    "fc_drop=list(map(float, fc_drop.split(',')))\n",
    "fc_use_laynorm_inp=str_to_bool(fc_use_laynorm_inp)\n",
    "fc_use_batchnorm_inp=str_to_bool(fc_use_batchnorm_inp)\n",
    "fc_use_batchnorm=list(map(str_to_bool, fc_use_batchnorm.split(',')))\n",
    "fc_use_laynorm=list(map(str_to_bool, fc_use_laynorm.split(',')))\n",
    "fc_act=list(map(str, fc_act.split(',')))\n",
    "\n",
    "#[class]\n",
    "class_lay=list(map(int, class_lay.split(',')))\n",
    "class_drop=list(map(float, class_drop.split(',')))\n",
    "class_use_laynorm_inp=str_to_bool(class_use_laynorm_inp)\n",
    "class_use_batchnorm_inp=str_to_bool(class_use_batchnorm_inp)\n",
    "class_use_batchnorm=list(map(str_to_bool, class_use_batchnorm.split(',')))\n",
    "class_use_laynorm=list(map(str_to_bool, class_use_laynorm.split(',')))\n",
    "class_act=list(map(str, class_act.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d99dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wlen = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e74360",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      3\u001b[39m CNN_arch = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m'\u001b[39m: wlen,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfs\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(fs),\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcnn_drop\u001b[39m\u001b[33m'\u001b[39m:cnn_drop,          \n\u001b[32m     15\u001b[39m }\n\u001b[32m     18\u001b[39m CNN_net=SincNet(CNN_arch)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mCNN_net\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m DNN1_arch = {\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m'\u001b[39m: CNN_net.out_dim,\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfc_lay\u001b[39m\u001b[33m'\u001b[39m: fc_lay,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfc_act\u001b[39m\u001b[33m'\u001b[39m: fc_act,\n\u001b[32m     32\u001b[39m }\n\u001b[32m     34\u001b[39m DNN1_net=MLP(DNN1_arch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/academic/sem3/TrustworthyML-assignment/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1084\u001b[39m, in \u001b[36mModule.cuda\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Self:\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[32m   1069\u001b[39m \n\u001b[32m   1070\u001b[39m \u001b[33;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1082\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/academic/sem3/TrustworthyML-assignment/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/academic/sem3/TrustworthyML-assignment/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/academic/sem3/TrustworthyML-assignment/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/academic/sem3/TrustworthyML-assignment/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1084\u001b[39m, in \u001b[36mModule.cuda.<locals>.<lambda>\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Self:\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[32m   1069\u001b[39m \n\u001b[32m   1070\u001b[39m \u001b[33;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1082\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Feature extractor CNN\n",
    "CNN_arch = {\n",
    "    'input_dim': wlen,\n",
    "    'fs': int(fs),\n",
    "    'cnn_N_filt': cnn_N_filt,\n",
    "    'cnn_len_filt': cnn_len_filt,\n",
    "    'cnn_max_pool_len':cnn_max_pool_len,\n",
    "    'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "    'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "    'cnn_use_laynorm':cnn_use_laynorm,\n",
    "    'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "    'cnn_act': cnn_act,\n",
    "    'cnn_drop':cnn_drop,          \n",
    "}\n",
    "\n",
    "\n",
    "CNN_net=SincNet(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "DNN1_arch = {\n",
    "    'input_dim': CNN_net.out_dim,\n",
    "    'fc_lay': fc_lay,\n",
    "    'fc_drop': fc_drop, \n",
    "    'fc_use_batchnorm': fc_use_batchnorm,\n",
    "    'fc_use_laynorm': fc_use_laynorm,\n",
    "    'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "    'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "    'fc_act': fc_act,\n",
    "}\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "\n",
    "\n",
    "DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "          'fc_lay': class_lay,\n",
    "          'fc_drop': class_drop, \n",
    "          'fc_use_batchnorm': class_use_batchnorm,\n",
    "          'fc_use_laynorm': class_use_laynorm,\n",
    "          'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "          'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "# %%\n",
    "inp = torch.randn(2,  wlen).cuda()\n",
    "out1 = CNN_net(inp)\n",
    "print(out1.shape)\n",
    "\n",
    "print(CNN_net.out_dim)\n",
    "out2 = DNN1_net(out1)\n",
    "print(out2.shape)\n",
    "\n",
    "# %%\n",
    "pout=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "print(pout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4902111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSincNet(nn.Module):\n",
    "    def __init__(self, num_class, fs=6000, wlen=4000):\n",
    "        super(FullSincNet, self).__init__()\n",
    "        # %%\n",
    "        # Feature extractor CNN\n",
    "        self.CNN_arch = {\n",
    "            'input_dim': wlen,\n",
    "            'fs': int(fs),\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt': cnn_len_filt,\n",
    "            'cnn_max_pool_len':cnn_max_pool_len,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,          \n",
    "        }\n",
    "\n",
    "\n",
    "        self.CNN_net = SincNet(self.CNN_arch)\n",
    "\n",
    "\n",
    "\n",
    "        self.DNN1_arch = {\n",
    "            'input_dim': self.CNN_net.out_dim,\n",
    "            'fc_lay': fc_lay,\n",
    "            'fc_drop': fc_drop, \n",
    "            'fc_use_batchnorm': fc_use_batchnorm,\n",
    "            'fc_use_laynorm': fc_use_laynorm,\n",
    "            'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "            'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "            'fc_act': fc_act,\n",
    "        }\n",
    "\n",
    "        self.DNN1_net=MLP(self.DNN1_arch)\n",
    "\n",
    "\n",
    "        self.DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "                'fc_lay': [num_class],\n",
    "                'fc_drop': class_drop, \n",
    "                'fc_use_batchnorm': class_use_batchnorm,\n",
    "                'fc_use_laynorm': class_use_laynorm,\n",
    "                'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "                'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "                'fc_act': class_act,\n",
    "                }\n",
    "\n",
    "\n",
    "        self.DNN2_net=MLP(self.DNN2_arch)\n",
    "\n",
    "    def set_weights(self,weights_path):\n",
    "        \n",
    "        _weights = torch.load(weights_path, weights_only=False)\n",
    "        self.CNN_net.load_state_dict(_weights['CNN_net'])\n",
    "        self.DNN1_net.load_state_dict(_weights['DNN1_net'])\n",
    "        self.DNN2_net.load_state_dict(_weights['DNN2_net'])\n",
    "        \n",
    "        self.id_map = _weights['speaker_to_id_map']\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN_net(x)\n",
    "        x = self.DNN1_net(x)\n",
    "        x = self.DNN2_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ebd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_classfier = FullSincNet(num_class=2)\n",
    "age_classfier = FullSincNet(num_class=3)\n",
    "accent_classfier = FullSincNet(num_class=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb12b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_classfier.set_weights(\"/home/desild/work/academic/sem3/TrustworthyML-assignment/tacotron2/vctk/models/SINCNET_GENDER/20251129_160107/checkpoint.pth\")\n",
    "age_classfier.set_weights(\"/home/desild/work/academic/sem3/TrustworthyML-assignment/tacotron2/vctk/models/SINCNET_AGEg/20251129_184806/checkpoint.pth\")\n",
    "accent_classfier.set_weights(\"/home/desild/work/academic/sem3/TrustworthyML-assignment/tacotron2/vctk/models/SINCNET_ACCENTS/20251129_173841/checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1062b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_classfier.cuda()\n",
    "age_classfier.cuda()\n",
    "accent_classfier.cuda()\n",
    "\n",
    "gender_classfier.eval()\n",
    "age_classfier.eval()\n",
    "accent_classfier.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_weights = torch.load(\"/home/desild/work/academic/sem3/TrustworthyML-assignment/tacotron2/vctk/models/SINCNET_SR/20251129_142613/checkpoint.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c82863",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_ids = sr_weights['speaker_to_id_map']\n",
    "\n",
    "id2speaker = {v: int(k) for k, v in speaker_ids.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453516a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 227,\n",
       " 1: 244,\n",
       " 2: 245,\n",
       " 3: 248,\n",
       " 4: 249,\n",
       " 5: 251,\n",
       " 6: 252,\n",
       " 7: 253,\n",
       " 8: 256,\n",
       " 9: 261,\n",
       " 10: 264,\n",
       " 11: 268,\n",
       " 12: 274,\n",
       " 13: 275,\n",
       " 14: 281,\n",
       " 15: 288,\n",
       " 16: 292,\n",
       " 17: 293,\n",
       " 18: 294,\n",
       " 19: 295,\n",
       " 20: 298,\n",
       " 21: 301,\n",
       " 22: 304,\n",
       " 23: 306,\n",
       " 24: 307,\n",
       " 25: 311,\n",
       " 26: 312,\n",
       " 27: 314,\n",
       " 28: 316,\n",
       " 29: 323,\n",
       " 30: 326,\n",
       " 31: 335,\n",
       " 32: 347,\n",
       " 33: 374,\n",
       " 34: 376}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{227: {'AGEg': '28<', 'GENDER': 'M', 'ACCENTS': 'English'},\n",
       " 244: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'English'},\n",
       " 245: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'Irish'},\n",
       " 248: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'Indian'},\n",
       " 249: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'Scottish'},\n",
       " 251: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'Indian'},\n",
       " 252: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'Scottish'},\n",
       " 253: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'Welsh'},\n",
       " 256: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'English'},\n",
       " 261: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'NorthernIrish'},\n",
       " 264: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'Scottish'},\n",
       " 268: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'English'},\n",
       " 274: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'English'},\n",
       " 275: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'Scottish'},\n",
       " 281: {'AGEg': '28<', 'GENDER': 'M', 'ACCENTS': 'Scottish'},\n",
       " 288: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'Irish'},\n",
       " 292: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'NorthernIrish'},\n",
       " 293: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'NorthernIrish'},\n",
       " 294: {'AGEg': '28<', 'GENDER': 'F', 'ACCENTS': 'American'},\n",
       " 295: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'Irish'},\n",
       " 298: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'Irish'},\n",
       " 301: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'American'},\n",
       " 304: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'NorthernIrish'},\n",
       " 306: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'American'},\n",
       " 307: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'Canadian'},\n",
       " 311: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'American'},\n",
       " 312: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'Canadian'},\n",
       " 314: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'SouthAfrican'},\n",
       " 316: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'Canadian'},\n",
       " 323: {'AGEg': '<20', 'GENDER': 'F', 'ACCENTS': 'SouthAfrican'},\n",
       " 326: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'Australian'},\n",
       " 335: {'AGEg': '20-28', 'GENDER': 'F', 'ACCENTS': 'NewZealand'},\n",
       " 347: {'AGEg': '20-28', 'GENDER': 'M', 'ACCENTS': 'SouthAfrican'},\n",
       " 374: {'AGEg': '28<', 'GENDER': 'M', 'ACCENTS': 'Australian'},\n",
       " 376: {'AGEg': '<20', 'GENDER': 'M', 'ACCENTS': 'Indian'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_data = pd.read_csv(\"/home/desild/work/academic/sem3/TrustworthyML-assignment/data/raw/vctk/train_data_top.csv\")\n",
    "speaker_data = speaker_data[[\"speaker_id\", \"AGEg\", \"GENDER\", \"ACCENTS\"]].drop_duplicates().reset_index(drop=True).set_index(\"speaker_id\").to_dict(orient=\"index\")\n",
    "speaker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816312b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': 0, 'M': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_classfier.id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d5ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20-28': 0, '28<': 1, '<20': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_classfier.id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf448def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'American': 0,\n",
       " 'Australian': 1,\n",
       " 'Canadian': 2,\n",
       " 'English': 3,\n",
       " 'Indian': 4,\n",
       " 'Irish': 5,\n",
       " 'NewZealand': 6,\n",
       " 'NorthernIrish': 7,\n",
       " 'Scottish': 8,\n",
       " 'SouthAfrican': 9,\n",
       " 'Welsh': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_classfier.id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "entity: 100%|██████████| 3150/3150 [00:17<00:00, 176.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "DATA_FOL = \"/home/desild/work/academic/sem3/TrustworthyML-assignment/tacotron2/vctk/inverted_samples\"\n",
    "\n",
    "full_data = []\n",
    "for init_types in list(os.listdir(DATA_FOL)):\n",
    "    for speaker_type in list(os.listdir(os.path.join(DATA_FOL, init_types))):\n",
    "        for inst_id in list(os.listdir(os.path.join(DATA_FOL, init_types, speaker_type))):\n",
    "            for method in list(os.listdir(os.path.join(DATA_FOL, init_types, speaker_type, inst_id))):\n",
    "                load_data = torch.load(os.path.join(DATA_FOL, init_types, speaker_type, inst_id, method))\n",
    "                if \"inverted_sample_gan\" in method and \"best_audio\" in load_data.keys():\n",
    "                    reload_data = copy.deepcopy(load_data)\n",
    "                    \n",
    "                    reload_data[\"best_x\"] = load_data[\"best_audio\"]\n",
    "                    reload_data[\"best_z\"] = load_data[\"best_x\"]\n",
    "                    del reload_data[\"best_audio\"]\n",
    "        \n",
    "                    full_data.append({\n",
    "                        \"init_types\": init_types,\n",
    "                        \"speaker_type\": int(speaker_type),\n",
    "                        \"inst_id\": inst_id,\n",
    "                        \"method\": method.split(\"_\")[-1].split(\".\")[0],\n",
    "                        \"path\": os.path.join(DATA_FOL, init_types, speaker_type, inst_id, method),\n",
    "                        **reload_data\n",
    "                    })\n",
    "                else:\n",
    "                    \n",
    "                    full_data.append({\n",
    "                        \"init_types\": init_types,\n",
    "                        \"speaker_type\": int(speaker_type),\n",
    "                        \"inst_id\": inst_id,\n",
    "                        \"method\": method.split(\"_\")[-1].split(\".\")[0],\n",
    "                        \"path\": os.path.join(DATA_FOL, init_types, speaker_type, inst_id, method),\n",
    "                        **load_data\n",
    "                    })\n",
    "\n",
    "with tqdm(total=len(full_data), desc=\"entity\") as pbar:\n",
    "    for dinstance in full_data:\n",
    "        # Training\n",
    "        if dinstance[\"best_x\"].shape[-1] > wlen:\n",
    "            x = dinstance[\"best_x\"][:,dinstance[\"best_x\"].shape[-1]//2-wlen//2:dinstance[\"best_x\"].shape[-1]//2+wlen//2]\n",
    "        else:\n",
    "            x = dinstance[\"best_x\"]\n",
    "        \n",
    "        prob = gender_classfier(x)\n",
    "        dinstance[\"pred_prob_gender\"] = prob.detach().cpu().numpy()\n",
    "        dinstance[\"pred_gender\"] = np.argmax(dinstance[\"pred_prob_gender\"], axis=1)[0]\n",
    "        dinstance[\"true_gender\"] = gender_classfier.id_map[speaker_data[id2speaker[dinstance[\"speaker_type\"]]][\"GENDER\"]]\n",
    "        \n",
    "        prob = age_classfier(x)\n",
    "        dinstance[\"pred_prob_age\"] = prob.detach().cpu().numpy()\n",
    "        dinstance[\"pred_age\"] = np.argmax(dinstance[\"pred_prob_age\"], axis=1)[0]\n",
    "        dinstance[\"true_age\"] = age_classfier.id_map[speaker_data[id2speaker[dinstance[\"speaker_type\"]]][\"AGEg\"]]\n",
    "        \n",
    "        prob = accent_classfier(x)\n",
    "        dinstance[\"pred_prob_accent\"] = prob.detach().cpu().numpy()\n",
    "        dinstance[\"pred_accent\"] = np.argmax(dinstance[\"pred_prob_accent\"], axis=1)[0]\n",
    "        dinstance[\"true_accent\"] = accent_classfier.id_map[speaker_data[id2speaker[dinstance[\"speaker_type\"]]][\"ACCENTS\"]]\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df = pd.DataFrame(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c444a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_types</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>inst_id</th>\n",
       "      <th>method</th>\n",
       "      <th>true_gender</th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>true_age</th>\n",
       "      <th>pred_age</th>\n",
       "      <th>true_accent</th>\n",
       "      <th>pred_accent</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13.171387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>std</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.324532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>sliding</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.878018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gan-std-transfer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.970984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gan-normaud-transfer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43.903828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>white_noise_tanh</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gan-normaud</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10.064466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>white_noise_tanh</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gan-normaud-750epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10.719225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>white_noise_tanh</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gan-std</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>17.994435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>white_noise_tanh</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gan-transfer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7.602250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>white_noise_tanh</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gan-750epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10.990172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            init_types  speaker_type inst_id                 method  \\\n",
       "0                zeros             8       1                    gan   \n",
       "1                zeros             8       1                    std   \n",
       "2                zeros             8       1                sliding   \n",
       "3                zeros             8       1       gan-std-transfer   \n",
       "4                zeros             8       1   gan-normaud-transfer   \n",
       "...                ...           ...     ...                    ...   \n",
       "3145  white_noise_tanh             7       2            gan-normaud   \n",
       "3146  white_noise_tanh             7       2  gan-normaud-750epochs   \n",
       "3147  white_noise_tanh             7       2                gan-std   \n",
       "3148  white_noise_tanh             7       2           gan-transfer   \n",
       "3149  white_noise_tanh             7       2          gan-750epochs   \n",
       "\n",
       "      true_gender  pred_gender  true_age  pred_age  true_accent  pred_accent  \\\n",
       "0               1            1         0         1            3            0   \n",
       "1               1            0         0         1            3            7   \n",
       "2               1            0         0         1            3            0   \n",
       "3               1            0         0         1            3            0   \n",
       "4               1            0         0         1            3            0   \n",
       "...           ...          ...       ...       ...          ...          ...   \n",
       "3145            0            0         2         0           10            4   \n",
       "3146            0            0         2         0           10            9   \n",
       "3147            0            0         2         0           10            2   \n",
       "3148            0            0         2         1           10            2   \n",
       "3149            0            0         2         0           10            9   \n",
       "\n",
       "      time_taken  \n",
       "0      13.171387  \n",
       "1       1.324532  \n",
       "2      17.878018  \n",
       "3      45.970984  \n",
       "4      43.903828  \n",
       "...          ...  \n",
       "3145   10.064466  \n",
       "3146   10.719225  \n",
       "3147   17.994435  \n",
       "3148    7.602250  \n",
       "3149   10.990172  \n",
       "\n",
       "[3150 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_df = full_data_df[[\"init_types\", \"speaker_type\", \"inst_id\", \"method\", \"true_gender\", \"pred_gender\",   \"true_age\", \"pred_age\",  \"true_accent\", \"pred_accent\",\"time_taken\"]]\n",
    "sel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc40ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_df[\"correct_gender\"] = (sel_df[\"true_gender\"] == sel_df[\"pred_gender\"]).astype(int)\n",
    "sel_df[\"correct_age\"] = (sel_df[\"true_age\"] == sel_df[\"pred_age\"]).astype(int)\n",
    "sel_df[\"correct_accent\"] = (sel_df[\"true_accent\"] == sel_df[\"pred_accent\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22713619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">correct_gender</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correct_age</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correct_accent</th>\n",
       "      <th colspan=\"2\" halign=\"left\">time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_types</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">laplace</th>\n",
       "      <th>gan</th>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.490197</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.415585</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>17.044098</td>\n",
       "      <td>10.779227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-750epochs</th>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>15.490664</td>\n",
       "      <td>9.106895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.444338</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.294951</td>\n",
       "      <td>19.053647</td>\n",
       "      <td>15.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-750epochs</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.390476</td>\n",
       "      <td>0.490197</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>15.757564</td>\n",
       "      <td>9.122201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-transfer</th>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.351605</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>21.890042</td>\n",
       "      <td>17.536383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.476941</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.444338</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>26.081910</td>\n",
       "      <td>9.880595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std-transfer</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.501280</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>29.085286</td>\n",
       "      <td>15.965088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-transfer</th>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>21.570164</td>\n",
       "      <td>15.859191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sliding</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>26.497959</td>\n",
       "      <td>2.910481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.497245</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.408921</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>8.988685</td>\n",
       "      <td>1.276582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">white_noise_tanh</th>\n",
       "      <th>gan</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.462514</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.330944</td>\n",
       "      <td>21.754153</td>\n",
       "      <td>13.510140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-750epochs</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.476941</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>16.324461</td>\n",
       "      <td>13.292992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud</th>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.498533</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.453921</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>19.047620</td>\n",
       "      <td>12.503837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-750epochs</th>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.462514</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.294951</td>\n",
       "      <td>15.109300</td>\n",
       "      <td>10.089652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-transfer</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.307715</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>20.602446</td>\n",
       "      <td>17.349249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std</th>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.490197</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.462514</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>27.488912</td>\n",
       "      <td>14.467622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std-transfer</th>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.330944</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>29.660024</td>\n",
       "      <td>15.914863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-transfer</th>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>21.636391</td>\n",
       "      <td>15.871833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sliding</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.415585</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>26.026756</td>\n",
       "      <td>2.715084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.501828</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.408921</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>8.895143</td>\n",
       "      <td>1.161251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">zeros</th>\n",
       "      <th>gan</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.473665</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.415585</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>16.567609</td>\n",
       "      <td>10.672162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-750epochs</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.438095</td>\n",
       "      <td>0.498533</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>18.652481</td>\n",
       "      <td>14.619322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud</th>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.490197</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.386825</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>19.610919</td>\n",
       "      <td>13.582715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-750epochs</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.281284</td>\n",
       "      <td>17.393183</td>\n",
       "      <td>10.772332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-normaud-transfer</th>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.307715</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.330944</td>\n",
       "      <td>23.173834</td>\n",
       "      <td>16.832950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.453921</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.386825</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>23.285308</td>\n",
       "      <td>9.626839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-std-transfer</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.294951</td>\n",
       "      <td>26.424254</td>\n",
       "      <td>12.136199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan-transfer</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>18.302509</td>\n",
       "      <td>11.422307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sliding</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.330944</td>\n",
       "      <td>15.228900</td>\n",
       "      <td>3.804819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>2.465628</td>\n",
       "      <td>1.058670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       correct_gender           correct_age  \\\n",
       "                                                 mean       std        mean   \n",
       "init_types       method                                                       \n",
       "laplace          gan                         0.609524  0.490197    0.219048   \n",
       "                 gan-750epochs               0.495238  0.502375    0.400000   \n",
       "                 gan-normaud                 0.476190  0.501828    0.266667   \n",
       "                 gan-normaud-750epochs       0.523810  0.501828    0.390476   \n",
       "                 gan-normaud-transfer        0.485714  0.502193    0.142857   \n",
       "                 gan-std                     0.657143  0.476941    0.266667   \n",
       "                 gan-std-transfer            0.533333  0.501280    0.161905   \n",
       "                 gan-transfer                0.495238  0.502375    0.161905   \n",
       "                 sliding                     0.523810  0.501828    0.161905   \n",
       "                 std                         0.571429  0.497245    0.209524   \n",
       "white_noise_tanh gan                         0.476190  0.501828    0.304762   \n",
       "                 gan-750epochs               0.514286  0.502193    0.342857   \n",
       "                 gan-normaud                 0.561905  0.498533    0.285714   \n",
       "                 gan-normaud-750epochs       0.504762  0.502375    0.304762   \n",
       "                 gan-normaud-transfer        0.476190  0.501828    0.104762   \n",
       "                 gan-std                     0.609524  0.490197    0.304762   \n",
       "                 gan-std-transfer            0.504762  0.502375    0.123810   \n",
       "                 gan-transfer                0.495238  0.502375    0.114286   \n",
       "                 sliding                     0.619048  0.487950    0.219048   \n",
       "                 std                         0.523810  0.501828    0.209524   \n",
       "zeros            gan                         0.666667  0.473665    0.219048   \n",
       "                 gan-750epochs               0.514286  0.502193    0.438095   \n",
       "                 gan-normaud                 0.609524  0.490197    0.180952   \n",
       "                 gan-normaud-750epochs       0.514286  0.502193    0.457143   \n",
       "                 gan-normaud-transfer        0.485714  0.502193    0.104762   \n",
       "                 gan-std                     0.714286  0.453921    0.180952   \n",
       "                 gan-std-transfer            0.400000  0.492248    0.114286   \n",
       "                 gan-transfer                0.400000  0.492248    0.114286   \n",
       "                 sliding                     0.542857  0.500549    0.114286   \n",
       "                 std                         0.600000  0.492248    0.114286   \n",
       "\n",
       "                                                 correct_accent            \\\n",
       "                                             std           mean       std   \n",
       "init_types       method                                                     \n",
       "laplace          gan                    0.415585       0.066667  0.250640   \n",
       "                 gan-750epochs          0.492248       0.076190  0.266575   \n",
       "                 gan-normaud            0.444338       0.095238  0.294951   \n",
       "                 gan-normaud-750epochs  0.490197       0.085714  0.281284   \n",
       "                 gan-normaud-transfer   0.351605       0.066667  0.250640   \n",
       "                 gan-std                0.444338       0.114286  0.319684   \n",
       "                 gan-std-transfer       0.370130       0.066667  0.250640   \n",
       "                 gan-transfer           0.370130       0.066667  0.250640   \n",
       "                 sliding                0.370130       0.114286  0.319684   \n",
       "                 std                    0.408921       0.076190  0.266575   \n",
       "white_noise_tanh gan                    0.462514       0.123810  0.330944   \n",
       "                 gan-750epochs          0.476941       0.085714  0.281284   \n",
       "                 gan-normaud            0.453921       0.085714  0.281284   \n",
       "                 gan-normaud-750epochs  0.462514       0.095238  0.294951   \n",
       "                 gan-normaud-transfer   0.307715       0.066667  0.250640   \n",
       "                 gan-std                0.462514       0.114286  0.319684   \n",
       "                 gan-std-transfer       0.330944       0.085714  0.281284   \n",
       "                 gan-transfer           0.319684       0.066667  0.250640   \n",
       "                 sliding                0.415585       0.085714  0.281284   \n",
       "                 std                    0.408921       0.085714  0.281284   \n",
       "zeros            gan                    0.415585       0.076190  0.266575   \n",
       "                 gan-750epochs          0.498533       0.085714  0.281284   \n",
       "                 gan-normaud            0.386825       0.076190  0.266575   \n",
       "                 gan-normaud-750epochs  0.500549       0.085714  0.281284   \n",
       "                 gan-normaud-transfer   0.307715       0.123810  0.330944   \n",
       "                 gan-std                0.386825       0.066667  0.250640   \n",
       "                 gan-std-transfer       0.319684       0.095238  0.294951   \n",
       "                 gan-transfer           0.319684       0.114286  0.319684   \n",
       "                 sliding                0.319684       0.123810  0.330944   \n",
       "                 std                    0.319684       0.114286  0.319684   \n",
       "\n",
       "                                       time_taken             \n",
       "                                             mean        std  \n",
       "init_types       method                                       \n",
       "laplace          gan                    17.044098  10.779227  \n",
       "                 gan-750epochs          15.490664   9.106895  \n",
       "                 gan-normaud            19.053647  15.467319  \n",
       "                 gan-normaud-750epochs  15.757564   9.122201  \n",
       "                 gan-normaud-transfer   21.890042  17.536383  \n",
       "                 gan-std                26.081910   9.880595  \n",
       "                 gan-std-transfer       29.085286  15.965088  \n",
       "                 gan-transfer           21.570164  15.859191  \n",
       "                 sliding                26.497959   2.910481  \n",
       "                 std                     8.988685   1.276582  \n",
       "white_noise_tanh gan                    21.754153  13.510140  \n",
       "                 gan-750epochs          16.324461  13.292992  \n",
       "                 gan-normaud            19.047620  12.503837  \n",
       "                 gan-normaud-750epochs  15.109300  10.089652  \n",
       "                 gan-normaud-transfer   20.602446  17.349249  \n",
       "                 gan-std                27.488912  14.467622  \n",
       "                 gan-std-transfer       29.660024  15.914863  \n",
       "                 gan-transfer           21.636391  15.871833  \n",
       "                 sliding                26.026756   2.715084  \n",
       "                 std                     8.895143   1.161251  \n",
       "zeros            gan                    16.567609  10.672162  \n",
       "                 gan-750epochs          18.652481  14.619322  \n",
       "                 gan-normaud            19.610919  13.582715  \n",
       "                 gan-normaud-750epochs  17.393183  10.772332  \n",
       "                 gan-normaud-transfer   23.173834  16.832950  \n",
       "                 gan-std                23.285308   9.626839  \n",
       "                 gan-std-transfer       26.424254  12.136199  \n",
       "                 gan-transfer           18.302509  11.422307  \n",
       "                 sliding                15.228900   3.804819  \n",
       "                 std                     2.465628   1.058670  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_df.groupby([\"init_types\", \"method\"]).agg({\"correct_gender\": [\"mean\", \"std\"], \"correct_age\": [\"mean\", \"std\"], \"correct_accent\": [\"mean\", \"std\"], \"time_taken\": [\"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
